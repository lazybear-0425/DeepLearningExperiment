{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ce7b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose, Resize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4450dcac",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bbf63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('use', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ad52e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameter\n",
    "epochs = 10\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecbb098",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([ToTensor(), Resize((96, 96)), Normalize(0, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305603f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = FashionMNIST('data', train=True, transform=transform, download=True)\n",
    "test_data = FashionMNIST('data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, pin_memory=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ffc97d",
   "metadata": {},
   "source": [
    "## Build ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd67c028",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, num_channel, protect=False, strides=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        self.need_protect = protect or strides > 1\n",
    "        \n",
    "        self.cnn_1 = nn.LazyConv2d(num_channel, kernel_size=3, padding=1, stride=strides)\n",
    "        self.bn_1 = nn.BatchNorm2d(num_channel)\n",
    "        self.cnn_2 = nn.LazyConv2d(num_channel, kernel_size=3, padding=1)\n",
    "        self.bn_2 = nn.BatchNorm2d(num_channel)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        if self.need_protect:\n",
    "            self.protect = nn.LazyConv2d(num_channel, kernel_size=1, stride=strides)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        Y = self.cnn_1(X)\n",
    "        Y = self.bn_1(Y)\n",
    "        Y = self.relu(Y)\n",
    "        \n",
    "        Y = self.cnn_2(Y)\n",
    "        Y = self.bn_2(Y)\n",
    "        Y = self.relu(Y)\n",
    "        \n",
    "        if self.need_protect:\n",
    "            protect = self.protect(X)\n",
    "        else:\n",
    "            protect = X\n",
    "        Y = Y + protect\n",
    "        \n",
    "        return self.relu(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560566a5",
   "metadata": {},
   "source": [
    "### Build My Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437f97d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        residual_block = [\n",
    "            ResidualBlock(64, protect=True),\n",
    "            ResidualBlock(128, strides=2, protect=True),\n",
    "            ResidualBlock(256, strides=2, protect=True),\n",
    "            ResidualBlock(512, strides=2, protect=True),\n",
    "        ]\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            *residual_block\n",
    "        )\n",
    "\n",
    "        self.start = nn.Sequential(\n",
    "                    nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
    "                    nn.LazyBatchNorm2d(), nn.ReLU(),\n",
    "                    nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "                    )\n",
    "        \n",
    "        self.last = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.start(X)\n",
    "        X = self.net(X)\n",
    "        X = self.last(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabe7ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(); model.to(device)\n",
    "loss = CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters())\n",
    "# schduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75ba3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (1, 96, 96))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01566e17",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f785610",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {\n",
    "    'acc':[],\n",
    "    'loss':[],\n",
    "    'val_acc':[],\n",
    "    'val_loss':[],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edcf3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record(acc, loss, val_acc, val_loss, needPrint=False):\n",
    "    global history\n",
    "    history['acc'].append(acc)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['loss'].append(loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    \n",
    "    if needPrint:\n",
    "        print(f'Training acc {acc:.4f}, loss {loss:.4f}')\n",
    "        print(f'Test acc {val_acc:.4f}, loss {val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f08076",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_val_acc = -1\n",
    "count = 0\n",
    "def EarlyStopping(patience=5):\n",
    "    global history, model\n",
    "    if last_val_acc >= history['val_acc'][-1]: \n",
    "        count += 1    \n",
    "        print('Not improve')\n",
    "    else:\n",
    "        torch.save(model.state_dict(), 'model.pt')\n",
    "        print('\\033[33m' + 'Save' + '\\033[0m')\n",
    "        \n",
    "    last_val_acc = history['val_acc'][-1]\n",
    "        \n",
    "    if count == patience: return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648e9f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epochs):\n",
    "    print(f'Epoch {i + 1} Start')\n",
    "    \n",
    "    model.train()\n",
    "    train_acc = 0\n",
    "    train_loss = 0\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        img, label = data\n",
    "        img, label = img.to(device), label.to(device)\n",
    "        \n",
    "        output = model(img)\n",
    "        output_loss = loss(output, label)\n",
    "        # Record\n",
    "        train_acc += (output.argmax(dim=1) == label).sum().item()\n",
    "        train_loss += output_loss.item()\n",
    "        # BP\n",
    "        output_loss.backward()\n",
    "        optimizer.step()\n",
    "    train_acc /= len(train_data)\n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "    model.eval()\n",
    "    test_acc = 0\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            img, label = data\n",
    "            img, label = img.to(device), label.to(device)\n",
    "            \n",
    "            output = model(img)\n",
    "            output_loss = loss(output, label)\n",
    "            # Record\n",
    "            test_acc += (output.argmax(dim=1) == label).sum().item()\n",
    "            test_loss += output_loss.item()\n",
    "    \n",
    "    test_acc /= len(test_data)\n",
    "    test_loss /= len(test_loader)\n",
    "    \n",
    "    record(train_acc, train_loss, train_acc, train_loss, True)\n",
    "    if EarlyStopping(5): break\n",
    "    print('==================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599d7b30",
   "metadata": {},
   "source": [
    "## Plot Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b66637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(name):\n",
    "    global device\n",
    "    plt.plot(history[name], 'b', label='train')\n",
    "    plt.plot(history['val_' + name], 'r', label='val')\n",
    "    plt.title('Performance')\n",
    "    plt.xlabel(name)\n",
    "    plt.ylabel('Epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d0e268",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot('acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8110f4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot('loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
